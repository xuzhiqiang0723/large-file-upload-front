/* eslint-disable unicorn/prefer-blob-reading-methods */
/* eslint-disable unicorn/prefer-add-event-listener */
import { computed, reactive, ref } from 'vue';

import SparkMD5 from 'spark-md5';

interface ChunkInfo {
  index: number;
  start: number;
  end: number;
  blob: Blob;
  hash: string;
  uploaded: boolean;
  progress: number;
  retryCount: number;
  uploadStartTime?: number;
  uploadEndTime?: number;
  uploadSpeed?: number; // bytes per second
}

interface UploadOptions {
  chunkSize?: number;
  concurrent?: number;
  retryTimes?: number;
  baseUrl?: string;
  headers?: Record<string, string>;
  hashChunkSize?: number;
}

interface UploadProgress {
  loaded: number;
  total: number;
  percentage: number;
}

interface HashProgress {
  loaded: number;
  total: number;
  percentage: number;
}

interface SpeedInfo {
  current: number; // å½“å‰é€Ÿåº¦ bytes/s
  average: number; // å¹³å‡é€Ÿåº¦ bytes/s
  peak: number; // å³°å€¼é€Ÿåº¦ bytes/s
  lastUpdate: number; // æœ€åæ›´æ–°æ—¶é—´æˆ³
}

interface NetworkStats {
  uploadedBytes: number;
  totalBytes: number;
  startTime: number;
  lastMeasureTime: number;
  lastMeasureBytes: number;
  speedHistory: number[]; // æœ€è¿‘10æ¬¡çš„é€Ÿåº¦è®°å½•
  chunkSpeeds: number[]; // åˆ†ç‰‡ä¸Šä¼ é€Ÿåº¦è®°å½•
}

interface CheckUploadResponse {
  success: boolean;
  shouldUpload: boolean;
  isComplete: boolean;
  message: string;
  url?: string;
  fileName?: string;
  uploadedChunks: string[];
  fileExists: boolean;
  resumeInfo?: {
    progress: number;
    totalChunks: number;
    uploadedCount: number;
  };
}

interface ChunkUploadResponse {
  success: boolean;
  message?: string;
  hash?: string;
  uploadedCount?: number;
  isExisting?: boolean;
}

interface MergeResponse {
  success: boolean;
  message?: string;
  url?: string;
  fileName?: string;
  originalName?: string;
  size?: number;
  fileHash?: string;
}

export function useUpload(options: UploadOptions = {}) {
  const {
    chunkSize = 5 * 1024 * 1024, // 5MB
    concurrent = 3,
    retryTimes = 3,
    baseUrl = '/api/upload',
    headers = {},
    hashChunkSize = 2 * 1024 * 1024, // 2MB for hash calculation
  } = options;

  // å“åº”å¼çŠ¶æ€
  const isUploading = ref(false);
  const isPaused = ref(false);
  const isCompleted = ref(false);
  const isCalculatingHash = ref(false);
  const isCheckingUpload = ref(false);
  const currentFile = ref<File | null>(null);
  const fileHash = ref('');
  const chunks = ref<ChunkInfo[]>([]);
  const uploadProgress = reactive<UploadProgress>({
    loaded: 0,
    total: 0,
    percentage: 0,
  });
  const hashProgress = reactive<HashProgress>({
    loaded: 0,
    total: 0,
    percentage: 0,
  });

  // ç½‘ç»œé€Ÿåº¦ç›¸å…³çŠ¶æ€
  const speedInfo = reactive<SpeedInfo>({
    current: 0,
    average: 0,
    peak: 0,
    lastUpdate: 0,
  });

  const networkStats = reactive<NetworkStats>({
    uploadedBytes: 0,
    totalBytes: 0,
    startTime: 0,
    lastMeasureTime: 0,
    lastMeasureBytes: 0,
    speedHistory: [],
    chunkSpeeds: [],
  });

  // æ–°å¢çŠ¶æ€
  const isSecondTransfer = ref(false);
  const resumeInfo = ref<any>(null);

  // è®¡ç®—å±æ€§
  const uploadedChunks = computed(() =>
    chunks.value.filter((chunk) => chunk.uploaded),
  );

  const remainingChunks = computed(() =>
    chunks.value.filter((chunk) => !chunk.uploaded),
  );

  const totalChunks = computed(() => chunks.value.length);

  const uploadedSize = computed(() =>
    uploadedChunks.value.reduce(
      (sum, chunk) => sum + (chunk.end - chunk.start),
      0,
    ),
  );

  // æ ¼å¼åŒ–é€Ÿåº¦æ˜¾ç¤º
  const formatSpeed = (bytesPerSecond: number): string => {
    if (bytesPerSecond === 0) return '0 B/s';

    if (bytesPerSecond >= 1024 * 1024 * 1024) {
      return `${(bytesPerSecond / (1024 * 1024 * 1024)).toFixed(2)} GB/s`;
    } else if (bytesPerSecond >= 1024 * 1024) {
      return `${(bytesPerSecond / (1024 * 1024)).toFixed(2)} MB/s`;
    } else if (bytesPerSecond >= 1024) {
      return `${(bytesPerSecond / 1024).toFixed(2)} KB/s`;
    } else {
      return `${bytesPerSecond.toFixed(0)} B/s`;
    }
  };

  // è®¡ç®—å‰©ä½™æ—¶é—´
  const calculateRemainingTime = (): string => {
    if (speedInfo.average <= 0) return 'è®¡ç®—ä¸­...';

    const remainingBytes = uploadProgress.total - uploadProgress.loaded;
    const remainingSeconds = remainingBytes / speedInfo.average;

    if (remainingSeconds > 3600) {
      const hours = Math.floor(remainingSeconds / 3600);
      const minutes = Math.floor((remainingSeconds % 3600) / 60);
      return `${hours}å°æ—¶${minutes}åˆ†é’Ÿ`;
    } else if (remainingSeconds > 60) {
      const minutes = Math.floor(remainingSeconds / 60);
      const seconds = Math.floor(remainingSeconds % 60);
      return `${minutes}åˆ†${seconds}ç§’`;
    } else {
      return `${Math.floor(remainingSeconds)}ç§’`;
    }
  };

  // æ›´æ–°ç½‘ç»œé€Ÿåº¦ç»Ÿè®¡
  const updateNetworkStats = (uploadedBytes: number) => {
    const now = Date.now();

    if (networkStats.startTime === 0) {
      networkStats.startTime = now;
      networkStats.lastMeasureTime = now;
      networkStats.lastMeasureBytes = uploadedBytes;
      return;
    }

    const timeDiff = now - networkStats.lastMeasureTime;
    if (timeDiff >= 1000) {
      // æ¯ç§’æ›´æ–°ä¸€æ¬¡
      const bytesDiff = uploadedBytes - networkStats.lastMeasureBytes;
      const currentSpeed = bytesDiff / (timeDiff / 1000);

      // æ›´æ–°å½“å‰é€Ÿåº¦
      speedInfo.current = currentSpeed;
      speedInfo.lastUpdate = now;

      // æ›´æ–°é€Ÿåº¦å†å²
      networkStats.speedHistory.push(currentSpeed);
      if (networkStats.speedHistory.length > 10) {
        networkStats.speedHistory.shift();
      }

      // è®¡ç®—å¹³å‡é€Ÿåº¦
      const totalTime = (now - networkStats.startTime) / 1000;
      speedInfo.average = totalTime > 0 ? uploadedBytes / totalTime : 0;

      // æ›´æ–°å³°å€¼é€Ÿåº¦
      if (currentSpeed > speedInfo.peak) {
        speedInfo.peak = currentSpeed;
      }

      networkStats.lastMeasureTime = now;
      networkStats.lastMeasureBytes = uploadedBytes;

      console.log(
        `ğŸ“ˆ ç½‘ç»œé€Ÿåº¦ - å½“å‰: ${formatSpeed(currentSpeed)}, å¹³å‡: ${formatSpeed(speedInfo.average)}, å³°å€¼: ${formatSpeed(speedInfo.peak)}`,
      );
    }
  };

  // é‡ç½®ç½‘ç»œç»Ÿè®¡
  const resetNetworkStats = () => {
    speedInfo.current = 0;
    speedInfo.average = 0;
    speedInfo.peak = 0;
    speedInfo.lastUpdate = 0;
    networkStats.uploadedBytes = 0;
    networkStats.totalBytes = 0;
    networkStats.startTime = 0;
    networkStats.lastMeasureTime = 0;
    networkStats.lastMeasureBytes = 0;
    networkStats.speedHistory = [];
    networkStats.chunkSpeeds = [];
  };

  /**
   * æ‰‹åŠ¨è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼
   */
  const calculateFileHash = async (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
      isCalculatingHash.value = true;
      hashProgress.loaded = 0;
      hashProgress.total = file.size;
      hashProgress.percentage = 0;

      const spark = new SparkMD5.ArrayBuffer();
      const totalChunks = Math.ceil(file.size / hashChunkSize);
      let currentChunkIndex = 0;
      let processedBytes = 0;

      console.log(
        `å¼€å§‹è®¡ç®—æ–‡ä»¶MD5ï¼Œæ–‡ä»¶å¤§å°: ${(file.size / 1024 / 1024).toFixed(2)}MB`,
      );
      console.log(
        `MD5è®¡ç®—åˆ†ç‰‡å¤§å°: ${(hashChunkSize / 1024 / 1024).toFixed(2)}MBï¼Œæ€»åˆ†ç‰‡æ•°: ${totalChunks}`,
      );

      const processNextChunk = () => {
        if (currentChunkIndex >= totalChunks) {
          const hash = spark.end();
          isCalculatingHash.value = false;
          console.log(`æ–‡ä»¶MD5è®¡ç®—å®Œæˆ: ${hash}`);
          resolve(hash);
          return;
        }

        const start = currentChunkIndex * hashChunkSize;
        const end = Math.min(start + hashChunkSize, file.size);
        const chunkBlob = file.slice(start, end);

        const fileReader = new FileReader();

        fileReader.onload = (e) => {
          try {
            if (e.target?.result) {
              spark.append(e.target.result as ArrayBuffer);
              processedBytes += chunkBlob.size;
              currentChunkIndex++;

              // æ›´æ–°è¿›åº¦
              hashProgress.loaded = processedBytes;
              hashProgress.percentage = Math.round(
                (processedBytes / file.size) * 100,
              );

              // æ¯10ä¸ªåˆ†ç‰‡æ‰“å°ä¸€æ¬¡è¿›åº¦
              if (
                currentChunkIndex % 10 === 0 ||
                currentChunkIndex === totalChunks
              ) {
                console.log(
                  `MD5è®¡ç®—è¿›åº¦: ${currentChunkIndex}/${totalChunks} (${hashProgress.percentage}%)`,
                );
              }

              // ä½¿ç”¨ setTimeout é¿å…é˜»å¡UIçº¿ç¨‹
              setTimeout(processNextChunk, 0);
            }
          } catch (error) {
            isCalculatingHash.value = false;
            console.error('MD5è®¡ç®—è¿‡ç¨‹ä¸­å‡ºé”™:', error);
            reject(new Error('MD5è®¡ç®—å¤±è´¥'));
          }
        };

        fileReader.onerror = (error) => {
          isCalculatingHash.value = false;
          console.error('æ–‡ä»¶è¯»å–å¤±è´¥:', error);
          reject(new Error('æ–‡ä»¶è¯»å–å¤±è´¥'));
        };

        fileReader.readAsArrayBuffer(chunkBlob);
      };

      // å¼€å§‹å¤„ç†ç¬¬ä¸€ä¸ªåˆ†ç‰‡
      processNextChunk();
    });
  };

  /**
   * æ‰‹åŠ¨è§¦å‘è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
   */
  const startCalculateHash = async (): Promise<void> => {
    if (!currentFile.value) {
      throw new Error('è¯·å…ˆé€‰æ‹©æ–‡ä»¶');
    }

    if (isCalculatingHash.value) {
      throw new Error('æ­£åœ¨è®¡ç®—ä¸­ï¼Œè¯·ç¨ç­‰...');
    }

    try {
      console.log('=== å¼€å§‹è®¡ç®—æ–‡ä»¶å“ˆå¸Œ ===');
      const calculatedHash = await calculateFileHash(currentFile.value);
      fileHash.value = calculatedHash;

      // è®¡ç®—å®Œå“ˆå¸Œåç«‹å³æ£€æŸ¥æ˜¯å¦å¯ä»¥ç§’ä¼ æˆ–æ–­ç‚¹ç»­ä¼ 
      await checkUploadStatus();

      console.log('=== æ–‡ä»¶å“ˆå¸Œè®¡ç®—å®Œæˆ ===');
    } catch (error) {
      console.error('=== æ–‡ä»¶å“ˆå¸Œè®¡ç®—å¤±è´¥ ===', error);
      throw error;
    }
  };

  /**
   * æ£€æŸ¥ä¸Šä¼ çŠ¶æ€ï¼ˆç§’ä¼ å’Œæ–­ç‚¹ç»­ä¼ æ£€æŸ¥ï¼‰
   */
  const checkUploadStatus = async (): Promise<CheckUploadResponse> => {
    if (!currentFile.value || !fileHash.value) {
      throw new Error('æ–‡ä»¶æˆ–å“ˆå¸Œå€¼ä¸å­˜åœ¨');
    }

    try {
      isCheckingUpload.value = true;
      console.log('ğŸ” æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ çŠ¶æ€...');

      const response = await fetch(`${baseUrl}/check`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...headers,
        },
        body: JSON.stringify({
          fileHash: fileHash.value,
          fileName: currentFile.value.name,
          fileSize: currentFile.value.size,
        }),
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result: CheckUploadResponse = await response.json();

      if (result.fileExists && result.isComplete) {
        // ç§’ä¼ æˆåŠŸ
        console.log('âš¡ ç§’ä¼ æˆåŠŸï¼æ–‡ä»¶å·²å­˜åœ¨');
        isSecondTransfer.value = true;
        isCompleted.value = true;
        return result;
      } else if (result.uploadedChunks.length > 0) {
        // å‘ç°æ–­ç‚¹ç»­ä¼ 
        console.log(
          `ğŸ”„ å‘ç°æ–­ç‚¹ç»­ä¼ ï¼Œå·²ä¸Šä¼  ${result.uploadedChunks.length} ä¸ªåˆ†ç‰‡`,
        );
        resumeInfo.value = result.resumeInfo;

        // åˆ›å»ºåˆ†ç‰‡å¹¶æ ‡è®°å·²ä¸Šä¼ çš„åˆ†ç‰‡
        createChunksAndMarkUploaded(
          currentFile.value,
          fileHash.value,
          result.uploadedChunks,
        );
      }

      return result;
    } catch (error) {
      console.error('æ£€æŸ¥ä¸Šä¼ çŠ¶æ€å¤±è´¥:', error);
      throw error;
    } finally {
      isCheckingUpload.value = false;
    }
  };

  /**
   * åˆ›å»ºåˆ†ç‰‡å¹¶æ ‡è®°å·²ä¸Šä¼ çš„åˆ†ç‰‡
   */
  const createChunksAndMarkUploaded = (
    file: File,
    fileHashValue: string,
    uploadedChunkHashes: string[],
  ) => {
    const fileChunks: ChunkInfo[] = [];
    const totalChunks = Math.ceil(file.size / chunkSize);

    console.log(
      `åˆ›å»ºåˆ†ç‰‡ï¼Œåˆ†ç‰‡å¤§å°: ${(chunkSize / 1024 / 1024).toFixed(2)}MBï¼Œæ€»æ•°: ${totalChunks}`,
    );

    for (let i = 0; i < totalChunks; i++) {
      const start = i * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      const blob = file.slice(start, end);
      const chunkHash = `${fileHashValue}_chunk_${i}`;

      const isUploaded = uploadedChunkHashes.includes(chunkHash);

      fileChunks.push({
        index: i,
        start,
        end,
        blob,
        hash: chunkHash,
        uploaded: isUploaded,
        progress: isUploaded ? 100 : 0,
        retryCount: 0,
      });
    }

    chunks.value = fileChunks;
    updateTotalProgress();

    console.log(
      `åˆ†ç‰‡åˆ›å»ºå®Œæˆï¼Œæ€»æ•°: ${fileChunks.length}ï¼Œå·²ä¸Šä¼ : ${uploadedChunkHashes.length}`,
    );
  };

  /**
   * åˆ›å»ºæ–‡ä»¶åˆ†ç‰‡
   */
  const createChunks = (file: File, fileHashValue: string): ChunkInfo[] => {
    const fileChunks: ChunkInfo[] = [];
    const totalChunks = Math.ceil(file.size / chunkSize);

    console.log(
      `å¼€å§‹åˆ›å»ºåˆ†ç‰‡ï¼Œåˆ†ç‰‡å¤§å°: ${(chunkSize / 1024 / 1024).toFixed(2)}MBï¼Œæ€»æ•°: ${totalChunks}`,
    );

    for (let i = 0; i < totalChunks; i++) {
      const start = i * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      const blob = file.slice(start, end);

      const chunkHash = `${fileHashValue}_chunk_${i}`;

      fileChunks.push({
        index: i,
        start,
        end,
        blob,
        hash: chunkHash,
        uploaded: false,
        progress: 0,
        retryCount: 0,
      });
    }

    console.log(`åˆ†ç‰‡åˆ›å»ºå®Œæˆï¼Œæ€»æ•°: ${fileChunks.length}`);
    return fileChunks;
  };

  /**
   * ä¸Šä¼ å•ä¸ªåˆ†ç‰‡ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«é€Ÿåº¦ç›‘æ§ï¼‰
   */
  const uploadChunk = async (chunk: ChunkInfo): Promise<boolean> => {
    const formData = new FormData();
    formData.append('chunk', chunk.blob);
    formData.append('chunkHash', chunk.hash);
    formData.append('fileHash', fileHash.value);
    formData.append('chunkIndex', chunk.index.toString());
    formData.append('fileName', currentFile.value?.name || '');
    formData.append('totalChunks', chunks.value.length.toString());

    try {
      chunk.progress = 1;
      chunk.uploadStartTime = Date.now();

      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 30_000);

      // åˆ›å»ºè‡ªå®šä¹‰çš„ XMLHttpRequest æ¥ç›‘æ§ä¸Šä¼ è¿›åº¦
      const xhr = new XMLHttpRequest();

      return new Promise((resolve, reject) => {
        xhr.upload.addEventListener('progress', (event) => {
          if (event.lengthComputable) {
            chunk.progress = Math.round((event.loaded / event.total) * 100);

            // æ›´æ–°æ€»ä½“è¿›åº¦å’Œç½‘ç»œé€Ÿåº¦
            const currentUploaded = uploadedSize.value + event.loaded;
            updateNetworkStats(currentUploaded);
            updateTotalProgress();
          }
        });

        xhr.addEventListener('load', () => {
          clearTimeout(timeoutId);

          if (xhr.status >= 200 && xhr.status < 300) {
            try {
              const result: ChunkUploadResponse = JSON.parse(xhr.responseText);

              if (result.success) {
                chunk.uploaded = true;
                chunk.progress = 100;
                chunk.uploadEndTime = Date.now();

                // è®¡ç®—åˆ†ç‰‡ä¸Šä¼ é€Ÿåº¦
                if (chunk.uploadStartTime && chunk.uploadEndTime) {
                  const uploadTime =
                    (chunk.uploadEndTime - chunk.uploadStartTime) / 1000;
                  const chunkSize = chunk.end - chunk.start;
                  const chunkSpeed = chunkSize / uploadTime;
                  chunk.uploadSpeed = chunkSpeed;
                  networkStats.chunkSpeeds.push(chunkSpeed);

                  console.log(
                    `âš¡ åˆ†ç‰‡ ${chunk.index} ä¸Šä¼ å®Œæˆï¼Œé€Ÿåº¦: ${formatSpeed(chunkSpeed)}`,
                  );
                }

                updateTotalProgress();

                if (result.isExisting) {
                  console.log(`âš¡ åˆ†ç‰‡ ${chunk.index} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¼ `);
                } else {
                  console.log(`âœ… åˆ†ç‰‡ ${chunk.index} ä¸Šä¼ æˆåŠŸ`);
                }

                resolve(true);
              } else {
                reject(new Error(result.message || 'åˆ†ç‰‡ä¸Šä¼ å¤±è´¥'));
              }
            } catch {
              reject(new Error('å“åº”è§£æå¤±è´¥'));
            }
          } else {
            reject(new Error(`HTTP ${xhr.status}: ${xhr.statusText}`));
          }
        });

        xhr.addEventListener('error', () => {
          clearTimeout(timeoutId);
          reject(new Error('ç½‘ç»œé”™è¯¯'));
        });

        xhr.addEventListener('timeout', () => {
          reject(new Error('ä¸Šä¼ è¶…æ—¶'));
        });

        xhr.open('POST', `${baseUrl}/chunk`);

        // è®¾ç½®è¯·æ±‚å¤´
        Object.entries(headers).forEach(([key, value]) => {
          xhr.setRequestHeader(key, value);
        });

        xhr.send(formData);
      });
    } catch (error) {
      console.error(`åˆ†ç‰‡ ${chunk.index} ä¸Šä¼ å¤±è´¥:`, error);
      chunk.retryCount++;
      chunk.progress = 0;
      return false;
    }
  };

  /**
   * æ›´æ–°æ€»ä½“ä¸Šä¼ è¿›åº¦
   */
  const updateTotalProgress = () => {
    if (!currentFile.value) return;

    const uploaded = uploadedSize.value;
    const total = currentFile.value.size;

    uploadProgress.loaded = uploaded;
    uploadProgress.total = total;
    uploadProgress.percentage =
      total > 0 ? Math.round((uploaded / total) * 100) : 0;
  };

  /**
   * å¹¶å‘ä¸Šä¼ åˆ†ç‰‡
   */
  const uploadChunksConcurrently = async (): Promise<void> => {
    const pendingChunks = [...remainingChunks.value];
    const executing: Promise<void>[] = [];

    console.log(
      `å¼€å§‹å¹¶å‘ä¸Šä¼  ${pendingChunks.length} ä¸ªåˆ†ç‰‡ï¼Œå¹¶å‘æ•°: ${concurrent}`,
    );

    const uploadSingleChunk = async (chunk: ChunkInfo): Promise<void> => {
      if (isPaused.value) return;

      let success = false;
      let attempts = 0;

      while (!success && attempts < retryTimes && !isPaused.value) {
        attempts++;
        success = await uploadChunk(chunk);

        if (!success && attempts < retryTimes) {
          console.log(`åˆ†ç‰‡ ${chunk.index} ç¬¬ ${attempts} æ¬¡é‡è¯•`);
          await new Promise((resolve) => setTimeout(resolve, 1000 * attempts));
        }
      }

      if (!success) {
        throw new Error(
          `åˆ†ç‰‡ ${chunk.index} ä¸Šä¼ å¤±è´¥ï¼Œå·²é‡è¯• ${retryTimes} æ¬¡`,
        );
      }
    };

    for (const chunk of pendingChunks) {
      if (isPaused.value) break;

      const promise = uploadSingleChunk(chunk).then(() => {
        executing.splice(executing.indexOf(promise), 1);
      });

      executing.push(promise);

      if (executing.length >= concurrent) {
        await Promise.race(executing);
      }
    }

    await Promise.all(executing);
    console.log('æ‰€æœ‰åˆ†ç‰‡ä¸Šä¼ å®Œæˆ');
  };

  /**
   * åˆå¹¶åˆ†ç‰‡
   */
  const mergeChunks = async (): Promise<MergeResponse> => {
    try {
      console.log(`å¼€å§‹åˆå¹¶åˆ†ç‰‡: ${baseUrl}/merge`);

      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 60_000);

      const response = await fetch(`${baseUrl}/merge`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...headers,
        },
        body: JSON.stringify({
          fileHash: fileHash.value,
          fileName: currentFile.value?.name,
          chunkHashes: chunks.value.map((chunk) => chunk.hash),
        }),
        signal: controller.signal,
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('åˆ†ç‰‡åˆå¹¶ç»“æœ:', result);

      return result;
    } catch (error) {
      console.error('åˆå¹¶åˆ†ç‰‡å¤±è´¥:', error);
      throw new Error(`åˆå¹¶åˆ†ç‰‡å¤±è´¥: ${error}`);
    }
  };

  /**
   * å¼€å§‹ä¸Šä¼ 
   */
  const startUpload = async (): Promise<null | string> => {
    if (!currentFile.value) {
      throw new Error('è¯·å…ˆé€‰æ‹©æ–‡ä»¶');
    }

    if (!fileHash.value) {
      throw new Error('è¯·å…ˆè®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼');
    }

    try {
      console.log('=== å¼€å§‹ä¸Šä¼ æµç¨‹ ===');
      console.log('æ–‡ä»¶ä¿¡æ¯:', {
        name: currentFile.value.name,
        size: `${(currentFile.value.size / 1024 / 1024).toFixed(2)}MB`,
        type: currentFile.value.type,
        hash: fileHash.value,
      });

      // é‡ç½®ç½‘ç»œç»Ÿè®¡
      resetNetworkStats();
      networkStats.totalBytes = currentFile.value.size;

      isUploading.value = true;
      isCompleted.value = false;
      isPaused.value = false;
      isSecondTransfer.value = false;

      // æ£€æŸ¥ä¸Šä¼ çŠ¶æ€
      console.log('æ­¥éª¤1: æ£€æŸ¥ä¸Šä¼ çŠ¶æ€...');
      const checkResult = await checkUploadStatus();

      if (checkResult.fileExists && checkResult.isComplete) {
        // ç§’ä¼ æˆåŠŸ
        console.log('âš¡ ç§’ä¼ æˆåŠŸï¼');
        isCompleted.value = true;
        isUploading.value = false;
        isSecondTransfer.value = true;
        return checkResult.url || null;
      }

      // å¦‚æœè¿˜æ²¡æœ‰åˆ›å»ºåˆ†ç‰‡ï¼Œç°åœ¨åˆ›å»º
      if (chunks.value.length === 0) {
        console.log('æ­¥éª¤2: åˆ›å»ºåˆ†ç‰‡...');
        chunks.value = createChunks(currentFile.value, fileHash.value);
      }

      updateTotalProgress();

      console.log(
        `æ–­ç‚¹ç»­ä¼ æ£€æŸ¥å®Œæˆï¼Œå·²ä¸Šä¼ : ${uploadedChunks.value.length}/${totalChunks.value}`,
      );

      // å¦‚æœæ‰€æœ‰åˆ†ç‰‡éƒ½å·²ä¸Šä¼ ï¼Œç›´æ¥åˆå¹¶
      if (uploadedChunks.value.length === totalChunks.value) {
        console.log('æ­¥éª¤3: æ‰€æœ‰åˆ†ç‰‡å·²å­˜åœ¨ï¼Œç›´æ¥åˆå¹¶...');
        const mergeResult = await mergeChunks();

        if (mergeResult.success) {
          isCompleted.value = true;
          isUploading.value = false;
          return mergeResult.url || null;
        } else {
          throw new Error(mergeResult.message || 'åˆå¹¶å¤±è´¥');
        }
      }

      // ä¸Šä¼ å‰©ä½™åˆ†ç‰‡
      console.log(`æ­¥éª¤3: å¼€å§‹ä¸Šä¼  ${remainingChunks.value.length} ä¸ªåˆ†ç‰‡...`);
      await uploadChunksConcurrently();

      // åˆå¹¶åˆ†ç‰‡
      console.log('æ­¥éª¤4: æ­£åœ¨åˆå¹¶åˆ†ç‰‡...');
      const mergeResult = await mergeChunks();

      if (mergeResult.success) {
        isCompleted.value = true;
        isUploading.value = false;

        // æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        console.log('=== ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯ ===');
        console.log(`å¹³å‡é€Ÿåº¦: ${formatSpeed(speedInfo.average)}`);
        console.log(`å³°å€¼é€Ÿåº¦: ${formatSpeed(speedInfo.peak)}`);
        console.log(
          `æ€»ç”¨æ—¶: ${((Date.now() - networkStats.startTime) / 1000).toFixed(2)}ç§’`,
        );

        return mergeResult.url || null;
      } else {
        throw new Error(mergeResult.message || 'åˆå¹¶å¤±è´¥');
      }
    } catch (error) {
      console.error('=== ä¸Šä¼ æµç¨‹å¤±è´¥ ===', error);
      isUploading.value = false;
      throw error;
    }
  };

  /**
   * æš‚åœä¸Šä¼ 
   */
  const pauseUpload = () => {
    console.log('æš‚åœä¸Šä¼ ');
    isPaused.value = true;
  };

  /**
   * æ¢å¤ä¸Šä¼ 
   */
  const resumeUpload = async (): Promise<null | string> => {
    if (!currentFile.value || isCompleted.value) {
      throw new Error('æ²¡æœ‰å¯æ¢å¤çš„ä¸Šä¼ ä»»åŠ¡');
    }

    console.log('æ¢å¤ä¸Šä¼ ');
    isPaused.value = false;
    isUploading.value = true;

    try {
      // ç»§ç»­ä¸Šä¼ å‰©ä½™åˆ†ç‰‡
      await uploadChunksConcurrently();

      // åˆå¹¶åˆ†ç‰‡
      const mergeResult = await mergeChunks();

      if (mergeResult.success) {
        isCompleted.value = true;
        isUploading.value = false;
        return mergeResult.url || null;
      } else {
        throw new Error(mergeResult.message || 'åˆå¹¶å¤±è´¥');
      }
    } catch (error) {
      isUploading.value = false;
      throw error;
    }
  };

  /**
   * å–æ¶ˆä¸Šä¼ 
   */
  const cancelUpload = () => {
    console.log('å–æ¶ˆä¸Šä¼ ');
    isPaused.value = true;
    isUploading.value = false;
    isCalculatingHash.value = false;
    isCheckingUpload.value = false;
    resetNetworkStats();
  };

  /**
   * é‡ç½®çŠ¶æ€
   */
  const reset = () => {
    console.log('é‡ç½®ä¸Šä¼ çŠ¶æ€');
    isUploading.value = false;
    isPaused.value = false;
    isCompleted.value = false;
    isCalculatingHash.value = false;
    isCheckingUpload.value = false;
    isSecondTransfer.value = false;
    currentFile.value = null;
    fileHash.value = '';
    chunks.value = [];
    resumeInfo.value = null;
    uploadProgress.loaded = 0;
    uploadProgress.total = 0;
    uploadProgress.percentage = 0;
    hashProgress.loaded = 0;
    hashProgress.total = 0;
    hashProgress.percentage = 0;
    resetNetworkStats();
  };

  return {
    // çŠ¶æ€
    isUploading,
    isPaused,
    isCompleted,
    isCalculatingHash,
    isCheckingUpload,
    isSecondTransfer,
    currentFile,
    fileHash,
    chunks,
    uploadProgress,
    hashProgress,
    resumeInfo,

    // ç½‘ç»œé€Ÿåº¦ç›¸å…³
    speedInfo,
    networkStats,
    formatSpeed,
    calculateRemainingTime,

    // è®¡ç®—å±æ€§
    uploadedChunks,
    remainingChunks,
    totalChunks,
    uploadedSize,

    // æ–¹æ³•
    startCalculateHash,
    checkUploadStatus,
    startUpload,
    pauseUpload,
    resumeUpload,
    cancelUpload,
    reset,
  };
}
